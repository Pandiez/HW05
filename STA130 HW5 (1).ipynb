{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea1055a",
   "metadata": {},
   "source": [
    "Q1.\n",
    "Measurability is the main factor in hypothesis testing that distinguishes between concepts that can be statistically tested and those that cannot. A hypothesis must be measurable, which means it can be tested statistically. A valid null hypothesis is testable, falsifiable, neutral, and specific. It acts as a baseline assumption, implying that there is no effect or difference across groups. The null hypothesis serves as a framework for testing whether observed data deviates considerably from this assumption. The alternative hypothesis, on the other hand, is what we hope to prove: there is a measurable effect or difference. The process of hypothesis testing entails accumulating evidence to either reject or fail to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f173fd3",
   "metadata": {},
   "source": [
    "Q2.\n",
    "The sentence implies that when we do a statistical test, we are attempting to learn about the population, which is the complete group we are interested in rather than just the sample, which is a smaller group we examine to represent the population. The sample mean is the sample's average value, but we are more interested in the population mean, which is the genuine average of the entire population. The test results are not only about the sample; they are intended to tell us something about the overall population based on the data we obtained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f607173",
   "metadata": {},
   "source": [
    "Q3.\n",
    "When calculating a p-value, we \"imagine a world where the null hypothesis is true\" because the p-value lets us assess how likely it is to acquire the outcomes we observed (or more extreme ones) if there is no effect or difference, as the null hypothesis states. Assuming the null hypothesis is true allows us to determine whether our data is unusual or surprising. If the evidence is extremely unlikely to occur in that \"null hypothesis world,\" we have reasons to question the null hypothesis and consider that something else could be true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ff5f0",
   "metadata": {},
   "source": [
    "Q4.\n",
    "A lower p-value indicates that the chances of receiving the outcomes we observed if the null hypothesis were true are extremely low. The p-value is the likelihood of encountering data similar to ours (or even more extreme), if the null hypothesis is valid. So, when the p-value is little, it indicates that our data is extremely improbable to occur by chance under the null hypothesis's \"no effect\" assumption. This makes the null hypothesis appear unlikely, prompting us to investigate whether the alternative hypothesis (which suggests an effect or difference) is more plausible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9dcbc",
   "metadata": {},
   "source": [
    "Q5. \n",
    "To calculate a p-value for the kissing head-tilt data, we can apply a \"50/50 coin-flipping\" model, which posits that there is no preference for left or right head-tilting.\n",
    "\n",
    "\n",
    "\n",
    "1. Null Hypothesis Setup: The null hypothesis (H₀) states that couples have no preference for tilting their heads left or right, and so the likelihood of tilting to the right is 0.5.\n",
    "\n",
    "2. The observed proportion of couples turning their heads to the right is 64.5% (80 out of 124 couples), or 0.645.\n",
    "\n",
    "3. Simulating the p-value: Using the 50/50 coin-flipping approach, we may simulate the p-value 10,000 times by randomly assigning 124 pairs a head tilt with a 50% chance in either direction. For each simulation, we would determine how many times the simulated number of right-tilted couples is at least as extreme as the observed number (80 or more).\n",
    "\n",
    "The p-value represents the fraction of these simulations in which 80 or more couples tilt their heads to the right.\n",
    "\n",
    "\n",
    "\n",
    "The simulated p-value is 0.0004, indicating the likelihood of seeing 80 or more couples bending their heads to the right assuming no true preference .\n",
    "\n",
    "Interpreting the p-value using the table:\n",
    "Our p-value of 0.0004 falls within the range of 0.001 ≥ 𝑝 0.001 ≥ p, indicating \"Very strong evidence against the null hypothesis\".\n",
    "This suggests that the observed head-tilt trend is unlikely to be related to chance, implying that couples may prefer to tilt their heads to the right when kissing.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73837c",
   "metadata": {},
   "source": [
    "Summary:\n",
    "Here is a summary of the questions you've asked:\n",
    "\n",
    "1. **Hypothesis Testing and Null Hypothesis**:\n",
    "   - What distinguishes ideas that can and cannot be tested statistically?\n",
    "   - What defines a good null hypothesis?\n",
    "   - What is the difference between a null hypothesis and an alternative hypothesis?\n",
    "\n",
    "2. **Population vs. Sample**:\n",
    "   - What does it mean that test outcomes refer to population parameters rather than sample statistics?\n",
    "\n",
    "3. **P-value Explanation**:\n",
    "   - Why do we \"imagine a world where the null hypothesis is true\" when calculating a p-value?\n",
    "   - Why does a smaller p-value make the null hypothesis seem more ridiculous?\n",
    "\n",
    "4. **Simulating a P-value**:\n",
    "   - How can we simulate a p-value using a 50/50 coin-flipping model for the kissing head-tilt study?\n",
    "   - What level of evidence do we have against the null hypothesis based on the simulated p-value?\n",
    "\n",
    "5. **P-value and Proof**:\n",
    "   - Can a smaller p-value definitively prove that the null hypothesis is false?\n",
    "   - Can a p-value definitively prove Fido is innocent or guilty?\n",
    "   - How low or high does a p-value have to be to definitively prove innocence or guilt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2803a",
   "metadata": {},
   "source": [
    "Link:\n",
    "https://chatgpt.com/share/670f2f8b-6634-800e-a369-e88513f437f4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52ebe1",
   "metadata": {},
   "source": [
    "Q6.\n",
    "No, a lower p-value cannot definitely prove that the null hypothesis is incorrect. A p-value shows us how likely our data is if the null hypothesis is true, but it does not provide absolute confidence. \n",
    "\n",
    "Fido cannot be definitively proven innocent or guilty using a p-value. A low p-value may indicate strong evidence against the null hypothesis (i.e., Fido's innocence), but it does not prove guilt or innocence. Similarly, a high p-value does not prove innocence; it only indicates that there is insufficient evidence to reject the null hypothesis.\n",
    "\n",
    "Regardless of how low or high the p-value is, it can only provide evidence for or against the null hypothesis and not definitive proof.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f221f2a",
   "metadata": {},
   "source": [
    "Q7.\n",
    "To modify the code for a one-sided hypothesis test rather than a two-sided test, change how the p-value is calculated based on your hypothesis. Here's an overview of the required changes and their implications:\n",
    "\n",
    "Changes to the Code P-value Calculation: For a two-tailed test, the p-value is derived by taking into account the likelihood of seeing a result as severe as or more extreme than the observed statistic in both directions (both tails). A one-tailed test considers only one direction (greater than or less than). Depending on your hypothesis, you would alter the p-value calculation accordingly. Here's how you can change the p-value computation in the code.\n",
    "\n",
    "Assuming 'observed_statistic' is the value of the test statistic\n",
    "and 'bootstrap_means' is your bootstrapped sampling distribution\n",
    "For one-tailed test (assuming testing if mean is greater than a null value)\n",
    "p_value = np.mean(bootstrap_means >= observed_statistic) # Right-tailed test\n",
    "\n",
    "For one-tailed test (assuming testing if mean is less than a null value)\n",
    "p_value = np.mean(bootstrap_means <= observed_statistic) # Left-tailed test\n",
    "Adjust the Confidence Interval:\n",
    "In a one-tailed test, you may also change the confidence interval. A 95% confidence level, for example, would only cover the lower or upper bounds in a left-tailed test, but not both. As a result, you would normally report only one important value rather than two. Changes in interpretation.\n",
    "\n",
    "Interpretation of P-values: In a one-tailed test, the p-value represents the likelihood of seeing findings that are as extreme or more extreme than the observed statistic in the given direction. This makes it easier because you're just evaluating one side of the distribution. A two-tailed test, on the other hand, evaluates extremes in both directions, which can result in a higher p-value because the significance level is divided over two tails.\n",
    "\n",
    "Decision Making: If you have a one-sided hypothesis (for example, whether the new vaccine is more successful than an existing one), a one-tailed test focuses entirely on that direction, which may lead to the null hypothesis being rejected more easily if the observed effect is in the expected direction. Expected differences in P-value\n",
    "\n",
    "P-value Size: In many circumstances, a one-tailed test's p-value should be less than or equal to that of a two-tailed test for the same data. The one-tailed test focuses all of the significance level (α) on one side of the distribution. For a 0.05 significance level, a two-tailed test divides the result into two tails, each with 0.025. A one-tailed test applies the whole 0.05 in one direction, increasing the likelihood of discovering significance.\n",
    "\n",
    "Conclusion Choosing between tests: The exact hypothesis and research issue should be considered when deciding whether to utilize a one-tailed or two-tailed test. It is critical to decide this before evaluating the data, as changing after viewing the results can lead to biased conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea6f87",
   "metadata": {},
   "source": [
    "Q8.\n",
    "Problem Introduction: The experiment analyzes if the sequence in which milk and tea are poured impacts people's ability to determine which was poured first. This study aims to assess whether STA130 students can accurately select the order by chance or if statistical data suggests that their ability to distinguish is stronger than random guessing.\n",
    "\n",
    "Relationship between this experiment and the first one with Fisher and Bristol: The original experiment done by Ronald Fisher and Dr. Muriel Bristol had a limited sample size (8 cups of tea) and was more individualized, concentrating on Bristol's tastes. In comparison, this research employs a larger sample size of 80 STA130 students, making it more abstract and statistical in character. The goal of both tests, however, is to determine whether there is a significant change in perception depending on the technique of preparation.\n",
    "\n",
    "\n",
    "Statements for the Null Hypothesis (H₀) and Alternative Hypothesis:\n",
    "\n",
    "Null Hypothesis (H0)\n",
    "The proportion of students who correctly identify the order of pouring equals the chance level (p = 0.5)\n",
    "\n",
    "Alternative Hypothesis (HA):\n",
    "The percentage of pupils who correctly identify the order of pouring above the chance level (p > 0.5).\n",
    "\n",
    "\n",
    "Methodology Code and Explanations Here’s how you can compute the z-test statistic and the p-value in Python:\n",
    "import numpy as np import scipy.stats as stats\n",
    "\n",
    "Data\n",
    "n = 80 # Total students x = 49 # Correct responses p_hat = x / n # Sample proportion\n",
    "\n",
    "Null hypothesis proportion\n",
    "p_0 = 0.5\n",
    "\n",
    "Calculate the z-test statistic\n",
    "z = (p_hat - p_0) / np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "Calculate the p-value for the one-tailed test\n",
    "p_value = 1 - stats.norm.cdf(z) # Right-tailed test\n",
    "\n",
    "print(f\"Z-test Statistic: {z:.4f}\") print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "Findings and Discussion: In this study, we tested if STA130 students could correctly detect the sequence in which milk and tea were poured using a sample of 80 students, with 49 successfully recognizing the order.\n",
    "\n",
    "The observed proportion of correct identifications was estimated as 𝑝 = 0.6125 (p=0.6125). This implies that more than half of the participants were able to discern the pouring order, raising the question of whether this result is statistically significant or simply due to chance.\n",
    "\n",
    "Hypothesis Testing: Using a one-sample z-test for proportions, we calculated the test statistic and p-value. The test statistic was 𝑧≈ 1.9743 z≈1.9743, resulting in a p-value of roughly 0.0240 (assuming a computed value based on the previously stated approach).\n",
    "\n",
    "Statistical Significance: The p-value (0.0240) is smaller than the significance level (𝛼 = 0.05 and α = 0.05). We reject the null hypothesis that students' ability to identify pouring order is equal to random guessing (𝑝 = 0.5, p=0.5).\n",
    "\n",
    "Interpretation: The findings indicate that STA130 students have a statistically significant capacity to distinguish between the pouring order of milk and tea, lending support to the theory that the way of preparation influences perception. This is consistent with Fisher's original findings, as Bristol's ability to discern between the two procedures was not due to chance.\n",
    "\n",
    "Limitations: While the sample size is bigger than Fisher's original experiment, it is still limited to students from a single course, which may not be representative of the whole population. Individual taste preferences or pouring order biases may also have an impact on the outcomes.\n",
    "\n",
    "Conclusion for the Null Hypothesis: Finally, the analysis shows substantial support against the null hypothesis, demonstrating that STA130 students can correctly discern between the order in which milk and tea are poured. The p-value obtained from the hypothesis test indicates that their ability to identify the pouring order is not due to random chance. This outcome echoes the essence of Fisher's original experiment and stresses the impact of preparation methods on sensory perception. Future research could include a more diverse sample and investigate additional aspects that may influence participants' assessments, so improving our understanding of sensory distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fd3ce",
   "metadata": {},
   "source": [
    "Q9.\n",
    "Yes, chatbot has assisted me by further enchancing my insight and solidifying my understanding of the concept on p-values within the statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517489f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
